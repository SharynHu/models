{
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "pytorch",
   "display_name": "pytorch",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "source": [
    "## The Cross Correlation Operation\n",
    "Suppose we have an input of shape $n_h \\times n_w$, and a kernel of shape $k_h \\times k_w$, after doing the cross correlation operation, the output shape is given by:\n",
    "$$(n_h-k_h+1) \\times (n_w-k_w+1)$$\n",
    "\n",
    "Illustration:\n",
    "<img src=\"./imgs/CNN/1.png\" alt=\"Cross Correlation Operation\" width=\"200\"/>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    n_h,n_w = X.shape\n",
    "    k_h,k_w = K.shape\n",
    "    Y = torch.zeros([n_h-k_h+1, n_w-k_w+1])\n",
    "    # print(Y)\n",
    "    for i in range(n_h-k_h+1):\n",
    "        for j in range(n_w-k_w+1):\n",
    "            Y[i][j] = (X[i:i+k_h, j:j+k_w]*K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "source": [
    "## Convolution layer\n",
    "A convolutional layer cross-correlates the input and kernel and adds a scalar bias to produce an output."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class Conv2D(torch.nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return corr2d(X, self.weight)+self.bias"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "source": [
    "## Convolutional layer for multiple input channels\n",
    "For a multi-channeled input, the kernel should have the same number of channels as it to do cross-correlation operation on each channel. The cross-correlation outputs will ben added up to get the final output.\n",
    "\n",
    "Here is the illustration:\n",
    "<img src=\"./imgs/CNN/conv-multi-in.svg\" width=\"400\"/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    return sum(corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "                  [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "source": [
    "## Convolutional layer for multiple input and output channels\n",
    "Denote by $c_i$ and $c_o$ the number of input and output channels, respectively, and let $k_h$ and $k_w$ be the height and width of the kernel. To get an output with multiple channels, we can create a kernel tensor of shape $c_i \\times k_h \\times k_w$ for every output channel. We concatenate them on the output channel dimension, so that the shape of the convolution kernel is $c_o \\times c_i \\times k_h \\times k_w$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "source": [
    "## $1 \\times 1$ convolution layer\n",
    "Because the minimum window is used, the $1 \\times 1$ convolution loses the ability of larger convolutional layers to recognize patterns consisting of interactions among adjacent elements in the height and width dimensions.  **The only computation of the $1 \\times 1$ convolution occurs on the channel dimension.**\n",
    "\n",
    "You could think of the $1 \\times 1$ convolutional layer as constituting a **fully-connected layer applied at every single pixel location** to transform the $c_i$ corresponding input values into $c_o$ output values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    "
   ]
  }
 ]
}